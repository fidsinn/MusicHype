{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for, flash\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio features import\n",
    "audio_features = pd.read_csv('../data/audio_features.csv')\n",
    "\n",
    "#spotify import\n",
    "sp_artist_release = pd.read_csv('../data/sp_artist_release.csv')\n",
    "sp_artist_track = pd.read_csv('../data/sp_artist_track.csv')\n",
    "sp_artist = pd.read_csv('../data/sp_artist.csv')\n",
    "sp_release = pd.read_csv('../data/sp_release.csv')\n",
    "sp_track = pd.read_csv('../data/sp_track.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5j/86vb95z109v6f0wkwc7b40240000gn/T/ipykernel_70599/3021875524.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  sampled_df = pd.concat([sampled_df, sampled_subset])\n"
     ]
    }
   ],
   "source": [
    "df_all = audio_features.merge(sp_track, on='isrc', how='inner')\n",
    "df_all = df_all.merge(sp_artist_track, on='track_id', how='inner')\n",
    "df_all = df_all.drop(columns=['updated_on_x'])\n",
    "df_all = df_all.merge(sp_artist, on='artist_id', how='inner')\n",
    "df_all = df_all.merge(sp_release, on='release_id', how='inner')\n",
    "\n",
    "df_all['duration_sec'] = df_all['duration_ms_x']/1000\n",
    "df_all['duration_sec'] = df_all['duration_sec'].round(0).astype(int)\n",
    "df_all = df_all.drop(columns=['duration_ms_x'])\n",
    "df_all = df_all[['isrc', 'release_id', 'track_title', 'artist_name','release_title', 'album_type', 'release_date', 'acousticness',\n",
    "                       'danceability', 'duration_sec', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness',\n",
    "                       'mode', 'speechiness', 'tempo', 'time_signature', 'valence', 'explicit', 'popularity']]\n",
    "\n",
    "df_all['key'] = df_all['key'].astype(str)\n",
    "df_all['mode'] = df_all['mode'].astype(str)\n",
    "df_all['time_signature'] = df_all['time_signature'].astype(str)\n",
    "df_all = df_all.drop(columns=['time_signature'])\n",
    "\n",
    "#df_all['release_year'] = df_all['release_date'].str.split('-').str[0].astype(int)\n",
    "#df_all = df_all[df_all['release_year']>=2000]\n",
    "df_all = df_all.drop(columns=['release_date'])\n",
    "\n",
    "df_all = df_all[df_all['acousticness'].between(0.0, 0.2)]\n",
    "df_all = df_all[df_all['danceability'].between(0.1, 1.0)]\n",
    "df_all = df_all[df_all['duration_sec'].between(60, 600)]\n",
    "df_all = df_all[df_all['energy'].between(0.0, 1.0)]\n",
    "df_all = df_all[df_all['liveness'].between(0.0, 0.4)]\n",
    "df_all = df_all[df_all['loudness'].between(-20.0, 0.0)]\n",
    "df_all = df_all[df_all['speechiness'].between(0.02, 0.4)]\n",
    "df_all = df_all[df_all['tempo'].between(70, 180)]\n",
    "#df_all = df_all[df_all['tempo'].between(50, 200)]\n",
    "\n",
    "pop_min = df_all['popularity'].min()\n",
    "pop_max = df_all['popularity'].max()\n",
    "df_all['popularity'] = round((df_all['popularity']-pop_min)/(pop_max-pop_min)*100, 0)\n",
    "\n",
    "df_all = df_all[(df_all['duration_sec']>=60) & (df_all['duration_sec']<=600)]\n",
    "\n",
    "#df_all['release_date'] = pd.to_datetime(df_all['release_date'], errors='coerce').dt.to_period('Y')\n",
    "\n",
    "df_all = df_all.groupby('isrc').agg({\n",
    "    'release_id': 'first',\n",
    "    'track_title': 'first',\n",
    "    'artist_name': 'first',\n",
    "    'release_title': 'first',\n",
    "    'album_type': 'first',\n",
    "    #'release_year': 'first',\n",
    "    'acousticness': 'first',\n",
    "    'danceability': 'first',\n",
    "    'duration_sec': 'first',\n",
    "    'energy': 'first',\n",
    "    'instrumentalness': 'first',\n",
    "    #'key': 'first',\n",
    "    'liveness': 'first',\n",
    "    'loudness': 'first',\n",
    "    #'mode': 'first',\n",
    "    'speechiness': 'first',\n",
    "    'tempo': 'first',\n",
    "    #'time_signature': 'first',\n",
    "    'valence': 'first',\n",
    "    #'explicit': 'first',\n",
    "    'popularity': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "df_all['popularity'] = df_all['popularity'].round(0).astype(int)\n",
    "\n",
    "#register min and max values of all columns that are standardized later\n",
    "#release year\n",
    "#release_year_min = df_all['release_year'].min()\n",
    "#release_year_max = df_all['release_year'].max()\n",
    "#acousticness\n",
    "acousticness_min = df_all['acousticness'].min()\n",
    "acousticness_max = df_all['acousticness'].max()\n",
    "#danceability\n",
    "danceability_min = df_all['danceability'].min()\n",
    "danceability_max = df_all['danceability'].max()\n",
    "#duration_sec\n",
    "duration_sec_min = df_all['duration_sec'].min()\n",
    "duration_sec_max = df_all['duration_sec'].max()\n",
    "#energy\n",
    "energy_min = df_all['energy'].min()\n",
    "energy_max = df_all['energy'].max()\n",
    "#instrumentalness\n",
    "instrumentalness_min = df_all['instrumentalness'].min()\n",
    "instrumentalness_max = df_all['instrumentalness'].max()\n",
    "#liveness\n",
    "liveness_min = df_all['liveness'].min()\n",
    "liveness_max = df_all['liveness'].max()\n",
    "#loudness\n",
    "loudness_min = df_all['loudness'].min()\n",
    "loudness_max = df_all['loudness'].max()\n",
    "#speechiness\n",
    "speechiness_min = df_all['speechiness'].min()\n",
    "speechiness_max = df_all['speechiness'].max()\n",
    "#tempo\n",
    "tempo_min = df_all['tempo'].min()\n",
    "tempo_max = df_all['tempo'].max()\n",
    "#valence\n",
    "valence_min = df_all['valence'].min()\n",
    "valence_max = df_all['valence'].max()\n",
    "#popularity\n",
    "popularity_min = df_all['popularity'].min()\n",
    "popularity_max = df_all['popularity'].max()\n",
    "\n",
    "# reduce lower popularity values to have a better distribution\n",
    "max_rows_per_value = 50000\n",
    "\n",
    "sampled_df = pd.DataFrame(columns=df_all.columns)\n",
    "\n",
    "for value in sorted(df_all['popularity'].unique()):\n",
    "    subset = df_all[df_all['popularity'] == value]\n",
    "    \n",
    "    if len(subset) > max_rows_per_value:\n",
    "        sampled_subset = subset.sample(n=max_rows_per_value, random_state=42)\n",
    "    else:\n",
    "        sampled_subset = subset\n",
    "    \n",
    "    sampled_df = pd.concat([sampled_df, sampled_subset])\n",
    "\n",
    "sampled_df = sampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "sampled_df.reset_index(drop=True, inplace=True)\n",
    "df_all = sampled_df\n",
    "\n",
    "df_all.to_csv('../data/df_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('../data/df_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acousticness_min: 0.0\n",
      "acousticness_max: 0.2\n",
      "danceability_min: 0.1\n",
      "danceability_max: 0.998\n",
      "duration_sec_min: 60\n",
      "duration_sec_max: 600\n",
      "energy_min: 2.02e-05\n",
      "energy_max: 1.0\n",
      "instrumentalness_min: 0.0\n",
      "instrumentalness_max: 1.0\n",
      "liveness_min: 0.00381\n",
      "liveness_max: 0.4\n",
      "loudness_min: -20.0\n",
      "loudness_max: 0.0\n",
      "speechiness_min: 0.0217\n",
      "speechiness_max: 0.4\n",
      "tempo_min: 70\n",
      "tempo_max: 180\n",
      "valence_min: 0.0\n",
      "valence_max: 1.0\n",
      "popularity_min: 0\n",
      "popularity_max: 100\n"
     ]
    }
   ],
   "source": [
    "#print('release_year_min:', release_year_min)\n",
    "#print('release_year_max:', release_year_max)\n",
    "print('acousticness_min:', acousticness_min)\n",
    "print('acousticness_max:', acousticness_max)\n",
    "print('danceability_min:', danceability_min)\n",
    "print('danceability_max:', danceability_max)\n",
    "print('duration_sec_min:', duration_sec_min)\n",
    "print('duration_sec_max:', duration_sec_max)\n",
    "print('energy_min:', energy_min)\n",
    "print('energy_max:', energy_max)\n",
    "print('instrumentalness_min:', instrumentalness_min)\n",
    "print('instrumentalness_max:', instrumentalness_max)\n",
    "print('liveness_min:', liveness_min)\n",
    "print('liveness_max:', liveness_max)\n",
    "print('loudness_min:', loudness_min)\n",
    "print('loudness_max:', loudness_max)\n",
    "print('speechiness_min:', speechiness_min)\n",
    "print('speechiness_max:', speechiness_max)\n",
    "print('tempo_min:', tempo_min)\n",
    "print('tempo_max:', tempo_max)\n",
    "print('valence_min:', valence_min)\n",
    "print('valence_max:', valence_max)\n",
    "print('popularity_min:', popularity_min)\n",
    "print('popularity_max:', popularity_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = [\n",
    "                    #'release_year',\n",
    "                    'acousticness',\n",
    "                    'danceability',\n",
    "                    'duration_sec',\n",
    "                    'energy',\n",
    "                    'instrumentalness',\n",
    "                    'liveness',\n",
    "                    'loudness',\n",
    "                    'speechiness',\n",
    "                    'tempo',\n",
    "                    #'time_signature',\n",
    "                    'valence'\n",
    "                    ]\n",
    "\n",
    "#STANDARD SCALER: scale numeric columns\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "#MINMAX SCALER: scale numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "pickle.dump(scaler, open('../models/minmaxscaler.sav', 'wb'))\n",
    "joblib.dump(scaler, '../models/minmax_scaler.pkl')\n",
    "\n",
    "df_all_scaled = df_all.copy()\n",
    "df_all_scaled[columns_to_scale] = scaler.fit_transform(df_all_scaled[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all_scaled.drop(columns=['popularity'])\n",
    "#object_columns = X.select_dtypes(include=['object']).columns\n",
    "#X = pd.get_dummies(X, columns=object_columns)\n",
    "\n",
    "y = df_all_scaled['popularity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train_knn = X_train.copy()\n",
    "X_train = X_train.drop(columns=['isrc', 'release_id', 'track_title', 'artist_name','release_title', 'album_type'])\n",
    "X_test = X_test.drop(columns=['isrc', 'release_id', 'track_title', 'artist_name','release_title', 'album_type'])\n",
    "\n",
    "X.to_csv('../data/X.csv', index=False)\n",
    "X_train.to_csv('../data/X_train.csv', index=False)\n",
    "X_train_knn.to_csv('../data/X_train_knn.csv', index=False)\n",
    "y_train.to_csv('../data/y_train.csv', index=False)\n",
    "X_test.to_csv('../data/X_test.csv', index=False)\n",
    "y_test.to_csv('../data/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../data/X.csv')\n",
    "X_train = pd.read_csv('../data/X_train.csv')\n",
    "X_train_knn = pd.read_csv('../data/X_train_knn.csv')\n",
    "y_train = pd.read_csv('../data/y_train.csv')\n",
    "X_test = pd.read_csv('../data/X_test.csv')\n",
    "y_test = pd.read_csv('../data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1083.7863123464945\n",
      "Root Mean Squared Error: 32.92090995623442\n"
     ]
    }
   ],
   "source": [
    "regression_model_load = True\n",
    "\n",
    "if regression_model_load:\n",
    "    regression_model = pickle.load(open('../models/regression_model.pkl', 'rb'))\n",
    "\n",
    "else:\n",
    "    regression_model = LinearRegression()\n",
    "    regression_model.fit(X_train, y_train)\n",
    "    pickle.dump(regression_model, open('../models/regression_model.pkl', 'wb'))\n",
    "\n",
    "y_pred = regression_model.predict(X_test)\n",
    "\n",
    "pop_pred_min = y_pred.min()\n",
    "pop_pred_max = y_pred.max()\n",
    "\n",
    "y_pred = (y_pred-pop_pred_min)/(pop_pred_max-pop_pred_min)*100\n",
    "y_pred = np.round(y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "rmse = math.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/finn/Desktop/MusicHype/musichype_env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/finn/Desktop/MusicHype/musichype_env/lib/python3.9/site-packages/xgboost/data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "/Users/finn/Desktop/MusicHype/musichype_env/lib/python3.9/site-packages/xgboost/data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "/Users/finn/Desktop/MusicHype/musichype_env/lib/python3.9/site-packages/xgboost/data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "/Users/finn/Desktop/MusicHype/musichype_env/lib/python3.9/site-packages/xgboost/data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 288.4320501817348\n",
      "Root Mean Squared Error: 16.98328737852995\n"
     ]
    }
   ],
   "source": [
    "xgboost_model_load = True\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_tt = label_encoder.fit_transform(y_train)\n",
    "\n",
    "if xgboost_model_load:\n",
    "    xgboost_model = pickle.load(open('../models/xgboost_model.pkl', 'rb'))\n",
    "\n",
    "else:\n",
    "    xgboost_model = xgb.XGBClassifier()\n",
    "    xgboost_model.fit(X_train, y_train_tt)\n",
    "    pickle.dump(xgboost_model, open('../models/xgboost_model.pkl', 'wb'))\n",
    "\n",
    "y_pred_encoded = xgboost_model.predict(X_test)\n",
    "y_pred_original = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "pop_pred_min = y_pred_original.min()\n",
    "pop_pred_max = y_pred_original.max()\n",
    "\n",
    "y_pred_original = (y_pred_original-pop_pred_min)/(pop_pred_max-pop_pred_min)*100\n",
    "y_pred_original = np.round(y_pred_original).astype(int)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_original)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "rmse = math.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dein Song hat eine erwartete Popularität von 13% und liegt über 59% aller anderen Songs\n",
      "Dein Song hat eine erwartete Popularität von 21% und liegt über 75% aller anderen Songs\n",
      "Dein Song hat eine erwartete Popularität von 21% und liegt über 75% aller anderen Songs\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame for the new data you want to make predictions on\n",
    "sample_data = {\n",
    "    #'release_year': [0.995, 0.90, 0.99],\n",
    "    'acousticness': [1.0, 0.5, 0.053313],\n",
    "    'danceability': [1.0, 0.5, 0.763000],\n",
    "    'duration_sec': [0.43, 0.14, 0.28],\n",
    "    'energy': [1.0, 0.5, 0.628000],\n",
    "    'instrumentalness': [1.0, 0.5, 0.000000],\n",
    "    'liveness':[1.0, 0.5, 0.114000],\n",
    "    'loudness': [1.0, 0.5, 0.826907],\n",
    "    'speechiness': [1.0, 0.5, 0.051653],\n",
    "    #'time_signature',\n",
    "    'tempo': [1.0, 0.5, 0.564000],\n",
    "    'valence': [1.0, 0.5, 0.193000]\n",
    "}\n",
    "\n",
    "columns_to_scale = [\n",
    "                    #'release_year',\n",
    "                    'acousticness',\n",
    "                    'danceability',\n",
    "                    'duration_sec',\n",
    "                    'energy',\n",
    "                    'instrumentalness',\n",
    "                    'liveness',\n",
    "                    'loudness',\n",
    "                    'speechiness',\n",
    "                    'tempo',\n",
    "                    #'time_signature',\n",
    "                    'valence'\n",
    "                    ]\n",
    "\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "\n",
    "predictions = regression_model.predict(sample_df)\n",
    "\n",
    "for i in predictions:\n",
    "    i = i[0]\n",
    "    pop_under = df_all[df_all['popularity']<=i].shape[0]\n",
    "    pop_all = df_all.shape[0]\n",
    "    pop_place = pop_under/pop_all*100\n",
    "    pop_place = int(round(pop_place, 0))\n",
    "    i = int(round(i, 0))\n",
    "    print(\"Dein Song hat eine erwartete Popularität von %s%% und liegt über %s%% aller anderen Songs\"%(i, pop_place))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dein Song hat eine erwartete Popularität von 13% und liegt über 59% aller anderen Songs\n",
    "Dein Song hat eine erwartete Popularität von 21% und liegt über 75% aller anderen Songs\n",
    "Dein Song hat eine erwartete Popularität von 21% und liegt über 75% aller anderen Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = joblib.load('../models/minmax_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with regression model\n",
      "Dein Song hat eine erwartete Popularität von 38 und liegt über 92% aller anderen Songs\n",
      "Dein Song hat eine erwartete Popularität von 37 und liegt über 92% aller anderen Songs\n",
      "Dein Song hat eine erwartete Popularität von 34 und liegt über 90% aller anderen Songs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/finn/Desktop/MusicHype/musichype_env/lib/python3.9/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred_model = 'regression' # regression or xgboost\n",
    "\n",
    "# Create a new DataFrame for the new data you want to make predictions on\n",
    "\n",
    "sample_data = {\n",
    "    #'release_year': [2000],\n",
    "    'acousticness': [0.5],\n",
    "    'danceability': [0.5],\n",
    "    'duration_sec': [130],\n",
    "    'energy': [0.5],\n",
    "    'instrumentalness': [0.5],\n",
    "    'liveness':[0.5],\n",
    "    'loudness': [1],\n",
    "    'speechiness': [0.5],\n",
    "    #'time_signature',\n",
    "    'tempo': [100],\n",
    "    'valence': [0.5]\n",
    "}\n",
    "\n",
    "sample_data = {\n",
    "    #'release_year': [2022],\n",
    "    'acousticness': [0.00453],\n",
    "    'danceability': [0.545],\n",
    "    'duration_sec': [215],\n",
    "    'energy': [0.641],\n",
    "    'instrumentalness': [0.000066],\n",
    "    'liveness':[0.171],\n",
    "    'loudness': [-6.3],\n",
    "    'speechiness': [0.0998],\n",
    "    #'time_signature',\n",
    "    'tempo': [122],\n",
    "    'valence': [0.464]\n",
    "}\n",
    "\n",
    "sample_data = {\n",
    "    #'release_year': [0.995, 0.90, 0.99],\n",
    "    'acousticness': [1.0, 0.5, 0.153313],\n",
    "    'danceability': [1.0, 0.5, 0.763000],\n",
    "    'duration_sec': [0.43, 0.14, 0.28],\n",
    "    'energy': [1.0, 0.5, 0.28000],\n",
    "    'instrumentalness': [1.0, 0.5, 0.000000],\n",
    "    'liveness':[1.0, 0.5, 0.114000],\n",
    "    'loudness': [1.0, 0.5, 0.826907],\n",
    "    'speechiness': [1.0, 0.5, 0.051653],\n",
    "    #'time_signature',\n",
    "    'tempo': [1.0, 0.5, 0.564000],\n",
    "    'valence': [1.0, 0.5, 0.193000]\n",
    "}\n",
    "\n",
    "columns_to_scale = [\n",
    "                    #'release_year',\n",
    "                    'acousticness',\n",
    "                    'danceability',\n",
    "                    'duration_sec',\n",
    "                    'energy',\n",
    "                    'instrumentalness',\n",
    "                    'liveness',\n",
    "                    'loudness',\n",
    "                    'speechiness',\n",
    "                    'tempo',\n",
    "                    #'time_signature',\n",
    "                    'valence'\n",
    "                    ]\n",
    "\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "\n",
    "df_all_scaled = df_all.copy()\n",
    "df_all_scaled[columns_to_scale] = scaler.fit_transform(df_all_scaled[columns_to_scale])\n",
    "\n",
    "sample_df_scaled = scaler.transform(sample_df)\n",
    "\n",
    "if pred_model == 'regression':\n",
    "    print('Predicting with regression model')\n",
    "    predictions = regression_model.predict(sample_df_scaled)\n",
    "elif pred_model == 'xgboost':\n",
    "    print('Predicting with xgboost model')\n",
    "    predictions = xgboost_model.predict(sample_df_scaled)\n",
    "\n",
    "for i in predictions:\n",
    "    if pred_model == 'regression':\n",
    "        i = i[0]\n",
    "    pop_under = df_all[df_all['popularity']<=i].shape[0]\n",
    "    pop_all = df_all.shape[0]\n",
    "    pop_place = pop_under/pop_all*100\n",
    "    pop_place = int(round(pop_place, 0))\n",
    "    i = int(round(i, 0))\n",
    "    print(\"Dein Song hat eine erwartete Popularität von %s und liegt über %s%% aller anderen Songs\"%(i, pop_place))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acousticness 0.0 - 0.2\n",
    "# danceability 0.1 - 1.0\n",
    "# duration_sec 60 - 600\n",
    "# energy 0.0 - 1.0\n",
    "\n",
    "# liveness 0.0 - 0.4\n",
    "# loudness -20 - 0.0\n",
    "# speechiness 0.02 - 0.4\n",
    "# tempo 70 - 180\n",
    "\n",
    "#plt.hist(df_all['valence'], bins=100)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344079\n",
      "isrc             GBQXM0600070\n",
      "track_title       That's Long\n",
      "artist_name         Dubbledge\n",
      "release_title    Fist of Jah!\n",
      "Name: 344079, dtype: object\n",
      "496529\n",
      "isrc              CA5KR0024530\n",
      "track_title      Oye Loco 2020\n",
      "artist_name         Nico Parga\n",
      "release_title      Guarachaton\n",
      "Name: 496529, dtype: object\n",
      "126687\n",
      "isrc                   USKO10800501\n",
      "track_title        That's A Soldier\n",
      "artist_name             Sheek Louch\n",
      "release_title    Silverback Gorilla\n",
      "Name: 126687, dtype: object\n"
     ]
    }
   ],
   "source": [
    "k = 3 # number of neighbors to find\n",
    "nn = NearestNeighbors(n_neighbors=k)\n",
    "nn.fit(X_train)\n",
    "\n",
    "distances, neighbor_indices = nn.kneighbors(sample_df_scaled)\n",
    "\n",
    "columns_sample_neighbors = ['isrc', 'track_title', 'artist_name','release_title']\n",
    "df_neighbors_info = pd.DataFrame(columns=columns_sample_neighbors)\n",
    "\n",
    "for i in list(X_train.iloc[neighbor_indices[0]].index):\n",
    "    print(i)\n",
    "    sample_neighbors = X_train.iloc[neighbor_indices[0]]\n",
    "    sample_neighbors = sample_neighbors.reset_index()\n",
    "    X_merger = X.reset_index()\n",
    "    sample_neighbors = sample_neighbors.merge(X_merger, on='index', how='inner')\n",
    "    sample_neighbors = sample_neighbors[['index', 'isrc', 'track_title', 'artist_name', 'release_title']]\n",
    "    sample_neighbors = sample_neighbors.merge(sp_release, on='release_title', how='inner')\n",
    "    print(X_train_knn.loc[i][['isrc', 'track_title', 'artist_name','release_title']])\n",
    "    df_neighbors_info_append = X_train_knn.loc[i][['isrc', 'track_title', 'artist_name','release_title']]\n",
    "    df_neighbors_info_append = pd.DataFrame(df_neighbors_info_append).T\n",
    "    #df_neighbors_info = df_neighbors_info.append(X_train_knn.loc[i][['isrc', 'track_title', 'artist_name','release_title']], ignore_index=True)\n",
    "    df_neighbors_info = pd.concat([df_neighbors_info, df_neighbors_info_append], axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musichype_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
